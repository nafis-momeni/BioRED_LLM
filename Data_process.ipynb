{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+VjwxXFauY3C/qFf5QTth",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nafis-momeni/BioRED_LLM/blob/main/Data_process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Mjo7fpJn2y-9"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import time\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/new_test.json') as file:\n",
        "    new_test = json.load(file)\n",
        "with open('/content/new_dev.json') as file:\n",
        "    new_dev = json.load(file)\n",
        "with open('/content/new_train.json') as file:\n",
        "    new_train = json.load(file)"
      ],
      "metadata": {
        "id": "FFaou8985LDx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "# Example data (filled with dummy values for illustration)\n",
        "\n",
        "train_stat = []\n",
        "\n",
        "# Extract statistics for each document\n",
        "for i in range(len(new_train)):\n",
        "    ent_type = {'GeneOrGeneProduct': 0, 'ChemicalEntity': 0, 'DiseaseOrPhenotypicFeature': 0,\n",
        "                'SequenceVariant': 0, 'OrganismTaxon': 0, 'CellLine': 0}\n",
        "    rel_type = {'Association': 0, 'Positive_Correlation': 0, 'Bind': 0, 'Negative_Correlation': 0,\n",
        "                'Comparison': 0, 'Conversion': 0, 'Cotreatment': 0, 'Drug_Interaction': 0}\n",
        "    rel_c = 0\n",
        "    novel = 0\n",
        "    doc = new_train[str(i)]\n",
        "    for e in doc[\"entities\"]:\n",
        "        ent_type[e[\"type\"]] += 1\n",
        "\n",
        "    for r in doc[\"relation\"]:\n",
        "        rel_type[r[\"infons\"][\"type\"]] += 1\n",
        "        rel_c += 1\n",
        "        if r[\"infons\"][\"novel\"] == \"Novel\":\n",
        "            novel += 1\n",
        "\n",
        "    stat = {\n",
        "        'pmid': doc['pmid'],\n",
        "        'ent_c': sum(value > 0 for value in ent_type.values()),\n",
        "        'rel_c': rel_c,\n",
        "        'g': ent_type['GeneOrGeneProduct'], 'c': ent_type['ChemicalEntity'], 'd': ent_type['DiseaseOrPhenotypicFeature'],\n",
        "        'v': ent_type['SequenceVariant'], 'o': ent_type['OrganismTaxon'], 'cl': ent_type['CellLine'],\n",
        "        'a': rel_type['Association'], 'pc': rel_type['Positive_Correlation'], 'b': rel_type['Bind'],\n",
        "        'nc': rel_type['Negative_Correlation'], 'cmp': rel_type['Comparison'], 'cnv': rel_type['Conversion'],\n",
        "        'ct': rel_type['Cotreatment'], 'di': rel_type['Drug_Interaction'],\n",
        "        'novel_ratio': novel / rel_c if rel_c > 0 else 0,\n",
        "        'ent_diversity': sum(value > 0 for value in ent_type.values()),\n",
        "        'rel_diversity': sum(value > 0 for value in rel_type.values())\n",
        "    }\n",
        "    train_stat.append(stat)\n",
        "\n"
      ],
      "metadata": {
        "id": "x4DKd3BWShcN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert test_stat to a structured array for easier manipulation\n",
        "features = ['ent_c', 'rel_c', 'g', 'c', 'd', 'v', 'o', 'cl', 'a', 'pc', 'b', 'nc', 'cmp', 'cnv', 'ct', 'di', 'novel_ratio', 'ent_diversity', 'rel_diversity']\n",
        "data_matrix = np.array([[stat[feature] for feature in features] for stat in train_stat])\n",
        "\n",
        "# Calculate the average values for each feature\n",
        "average_values = np.mean(data_matrix, axis=0)\n",
        "\n",
        "# Calculate similarity score based on Euclidean distance\n",
        "similarity_scores = np.array([1 / (1 + euclidean(sample, average_values)) for sample in data_matrix])\n",
        "\n",
        "# Normalize the similarity scores to get representativeness scores\n",
        "scaler = MinMaxScaler()\n",
        "representativeness_scores = scaler.fit_transform(similarity_scores.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Add representativeness scores to the original statistics\n",
        "for i, stat in enumerate(train_stat):\n",
        "    stat['representativeness_score'] = representativeness_scores[i]\n",
        "\n",
        "# Select top-k samples based on diversity scores\n",
        "k = 20  # Number of samples to select\n",
        "top_k_indices = np.argsort(representativeness_scores)[-k:]\n",
        "selected_samples = [train_stat[i] for i in top_k_indices]\n",
        "\n",
        "# Print the selected samples with diversity scores\n",
        "for stat in selected_samples:\n",
        "    print(stat)\n",
        "\n",
        "print(top_k_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkvoaJrBXVW0",
        "outputId": "32a68337-b388-48ec-c6a4-d8bfaf9b47a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pmid': '16575011', 'ent_c': 5, 'rel_c': 10, 'g': 1, 'c': 3, 'd': 3, 'v': 2, 'o': 1, 'cl': 0, 'a': 5, 'pc': 0, 'b': 0, 'nc': 3, 'cmp': 0, 'cnv': 0, 'ct': 2, 'di': 0, 'novel_ratio': 0.2, 'ent_diversity': 5, 'rel_diversity': 3, 'representativeness_score': 0.7602071860669584}\n",
            "{'pmid': '15122708', 'ent_c': 4, 'rel_c': 7, 'g': 3, 'c': 0, 'd': 4, 'v': 1, 'o': 1, 'cl': 0, 'a': 6, 'pc': 1, 'b': 0, 'nc': 0, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.2857142857142857, 'ent_diversity': 4, 'rel_diversity': 2, 'representativeness_score': 0.773053760850865}\n",
            "{'pmid': '28346429', 'ent_c': 3, 'rel_c': 8, 'g': 5, 'c': 0, 'd': 2, 'v': 0, 'o': 1, 'cl': 0, 'a': 5, 'pc': 0, 'b': 1, 'nc': 2, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.75, 'ent_diversity': 3, 'rel_diversity': 3, 'representativeness_score': 0.7734901884600571}\n",
            "{'pmid': '28098423', 'ent_c': 5, 'rel_c': 11, 'g': 7, 'c': 1, 'd': 3, 'v': 0, 'o': 1, 'cl': 1, 'a': 4, 'pc': 3, 'b': 1, 'nc': 3, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.6363636363636364, 'ent_diversity': 5, 'rel_diversity': 4, 'representativeness_score': 0.7747150306864494}\n",
            "{'pmid': '15609295', 'ent_c': 4, 'rel_c': 10, 'g': 4, 'c': 0, 'd': 2, 'v': 3, 'o': 1, 'cl': 0, 'a': 4, 'pc': 3, 'b': 3, 'nc': 0, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.4, 'ent_diversity': 4, 'rel_diversity': 3, 'representativeness_score': 0.7771561290091442}\n",
            "{'pmid': '20588063', 'ent_c': 4, 'rel_c': 7, 'g': 5, 'c': 1, 'd': 2, 'v': 0, 'o': 1, 'cl': 0, 'a': 6, 'pc': 1, 'b': 0, 'nc': 0, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.8571428571428571, 'ent_diversity': 4, 'rel_diversity': 2, 'representativeness_score': 0.7795732903469061}\n",
            "{'pmid': '18410508', 'ent_c': 4, 'rel_c': 12, 'g': 1, 'c': 4, 'd': 2, 'v': 0, 'o': 1, 'cl': 0, 'a': 8, 'pc': 3, 'b': 0, 'nc': 1, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.16666666666666666, 'ent_diversity': 4, 'rel_diversity': 3, 'representativeness_score': 0.781233033872025}\n",
            "{'pmid': '17006606', 'ent_c': 4, 'rel_c': 7, 'g': 3, 'c': 0, 'd': 2, 'v': 2, 'o': 1, 'cl': 0, 'a': 5, 'pc': 2, 'b': 0, 'nc': 0, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.42857142857142855, 'ent_diversity': 4, 'rel_diversity': 2, 'representativeness_score': 0.7914068045319063}\n",
            "{'pmid': '16410744', 'ent_c': 4, 'rel_c': 7, 'g': 4, 'c': 0, 'd': 2, 'v': 2, 'o': 1, 'cl': 0, 'a': 5, 'pc': 1, 'b': 0, 'nc': 1, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.7142857142857143, 'ent_diversity': 4, 'rel_diversity': 3, 'representativeness_score': 0.7951492114820464}\n",
            "{'pmid': '18262054', 'ent_c': 4, 'rel_c': 9, 'g': 1, 'c': 0, 'd': 2, 'v': 3, 'o': 1, 'cl': 0, 'a': 6, 'pc': 3, 'b': 0, 'nc': 0, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.7777777777777778, 'ent_diversity': 4, 'rel_diversity': 2, 'representativeness_score': 0.7995858047967834}\n",
            "{'pmid': '27643404', 'ent_c': 5, 'rel_c': 9, 'g': 3, 'c': 1, 'd': 2, 'v': 4, 'o': 1, 'cl': 0, 'a': 5, 'pc': 4, 'b': 0, 'nc': 0, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.7777777777777778, 'ent_diversity': 5, 'rel_diversity': 2, 'representativeness_score': 0.811542225951674}\n",
            "{'pmid': '24126708', 'ent_c': 5, 'rel_c': 10, 'g': 1, 'c': 2, 'd': 3, 'v': 3, 'o': 1, 'cl': 0, 'a': 4, 'pc': 2, 'b': 0, 'nc': 4, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.6, 'ent_diversity': 5, 'rel_diversity': 3, 'representativeness_score': 0.8140215958446237}\n",
            "{'pmid': '17572393', 'ent_c': 4, 'rel_c': 10, 'g': 4, 'c': 4, 'd': 1, 'v': 0, 'o': 1, 'cl': 0, 'a': 3, 'pc': 5, 'b': 0, 'nc': 2, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.9, 'ent_diversity': 4, 'rel_diversity': 3, 'representativeness_score': 0.8168423063472838}\n",
            "{'pmid': '16506214', 'ent_c': 5, 'rel_c': 12, 'g': 1, 'c': 2, 'd': 4, 'v': 2, 'o': 1, 'cl': 0, 'a': 7, 'pc': 2, 'b': 0, 'nc': 2, 'cmp': 0, 'cnv': 1, 'ct': 0, 'di': 0, 'novel_ratio': 0.3333333333333333, 'ent_diversity': 5, 'rel_diversity': 4, 'representativeness_score': 0.8217132781191192}\n",
            "{'pmid': '27825100', 'ent_c': 4, 'rel_c': 10, 'g': 5, 'c': 1, 'd': 2, 'v': 0, 'o': 1, 'cl': 0, 'a': 4, 'pc': 1, 'b': 0, 'nc': 5, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 1.0, 'ent_diversity': 4, 'rel_diversity': 3, 'representativeness_score': 0.8298335402925978}\n",
            "{'pmid': '20086182', 'ent_c': 5, 'rel_c': 9, 'g': 2, 'c': 1, 'd': 3, 'v': 3, 'o': 1, 'cl': 0, 'a': 7, 'pc': 2, 'b': 0, 'nc': 0, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.5555555555555556, 'ent_diversity': 5, 'rel_diversity': 2, 'representativeness_score': 0.8597766417790771}\n",
            "{'pmid': '28151486', 'ent_c': 4, 'rel_c': 8, 'g': 2, 'c': 1, 'd': 3, 'v': 0, 'o': 2, 'cl': 0, 'a': 5, 'pc': 1, 'b': 0, 'nc': 2, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.25, 'ent_diversity': 4, 'rel_diversity': 3, 'representativeness_score': 0.930167618464042}\n",
            "{'pmid': '24477591', 'ent_c': 5, 'rel_c': 10, 'g': 2, 'c': 1, 'd': 4, 'v': 1, 'o': 2, 'cl': 0, 'a': 7, 'pc': 3, 'b': 0, 'nc': 0, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.6, 'ent_diversity': 5, 'rel_diversity': 2, 'representativeness_score': 0.9615157996242516}\n",
            "{'pmid': '28411266', 'ent_c': 4, 'rel_c': 10, 'g': 2, 'c': 1, 'd': 2, 'v': 1, 'o': 0, 'cl': 0, 'a': 4, 'pc': 2, 'b': 0, 'nc': 4, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.6, 'ent_diversity': 4, 'rel_diversity': 3, 'representativeness_score': 0.9737183371332137}\n",
            "{'pmid': '28398555', 'ent_c': 5, 'rel_c': 11, 'g': 3, 'c': 3, 'd': 2, 'v': 2, 'o': 1, 'cl': 0, 'a': 6, 'pc': 4, 'b': 1, 'nc': 0, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.5454545454545454, 'ent_diversity': 5, 'rel_diversity': 3, 'representativeness_score': 1.0000000000000002}\n",
            "[ 85  10 294 109  71 327 366  19 168 283 279  46 358 196 201  76 320 225\n",
            "  56  95]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  set_5 = [363, 399,185,319, 339,196]\n",
        "  set_10 = set_5 + [263,288, 68, 359, 78]\n",
        "  set_15 = set_10 + [22, 368, 367, 373, 51]\n",
        "  zero_docs = [128,169,205,315,323, 363]\n",
        "#representiveness\n",
        "[85,  10, 294, 109, 71, 327, 366, 19 168 283, 279, 46, 358, 196, 201, 76, 320, 225, 56, 95]\n",
        "\n",
        "#diversity\n",
        "[322, 51,  78, 99, 355, 173, 368, 179, 371, 373, 339, 301, 288, 363, 185, 151,  22, 399, 263, 359, 196]\n",
        "\n",
        "#2\n",
        "[301, 319, 352,  22, 322,  78, 367, 151, 368,  51, 371, 355, 185, 373, 288, 263, 339, 196, 363, 359, 399]\n",
        "\n",
        "rep + dive\n",
        "[225, 56, 95, 363, 399]\n",
        "[196, 363, 399, 56, 95]"
      ],
      "metadata": {
        "id": "0qVo3rE8YwVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting and normalizing features\n",
        "features = ['ent_c', 'rel_c', 'g', 'c', 'd', 'v', 'o', 'cl', 'a', 'pc', 'b', 'nc', 'cmp', 'cnv', 'ct', 'di', 'novel_ratio', 'ent_diversity', 'rel_diversity']\n",
        "data_matrix = np.array([[stat[feature] for feature in features] for stat in train_stat])\n",
        "\n",
        "# Normalize the counts\n",
        "scaler = MinMaxScaler()\n",
        "normalized_data_matrix = scaler.fit_transform(data_matrix)\n",
        "\n",
        "# Assign higher weights to scarce relation types\n",
        "weights = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 3, 2, 2, 3, 1, 2, 6])\n",
        "weighted_data_matrix = normalized_data_matrix * weights\n",
        "\n",
        "# Calculate the composite scores\n",
        "composite_scores = weighted_data_matrix.sum(axis=1)\n",
        "\n",
        "# Normalize the composite scores\n",
        "normalized_composite_scores = scaler.fit_transform(composite_scores.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Add representativeness scores to the original statistics\n",
        "for i, stat in enumerate(train_stat):\n",
        "    stat['diversity_score'] = normalized_composite_scores[i]\n",
        "\n",
        "# Select top-k samples based on diversity scores\n",
        "k = 21  # Number of samples to select\n",
        "top_k_indices = np.argsort(normalized_composite_scores)[-k:]\n",
        "selected_samples = [train_stat[i] for i in top_k_indices]\n",
        "\n",
        "# Print the selected samples with diversity scores\n",
        "for stat in selected_samples:\n",
        "    print(stat)\n",
        "print(top_k_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1hz4ZygVdBM",
        "outputId": "25364b47-9206-46cd-c639-8edc3e325821"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pmid': '19463742', 'ent_c': 4, 'rel_c': 46, 'g': 12, 'c': 3, 'd': 0, 'v': 0, 'o': 2, 'cl': 2, 'a': 21, 'pc': 13, 'b': 1, 'nc': 11, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.8695652173913043, 'ent_diversity': 4, 'rel_diversity': 4, 'representativeness_score': 0.05281731918696182, 'diversity_score': 0.7155205827772616}\n",
            "{'pmid': '25218136', 'ent_c': 4, 'rel_c': 18, 'g': 14, 'c': 1, 'd': 1, 'v': 0, 'o': 1, 'cl': 0, 'a': 11, 'pc': 2, 'b': 3, 'nc': 2, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.6111111111111112, 'ent_diversity': 4, 'rel_diversity': 4, 'representativeness_score': 0.2576172195828939, 'diversity_score': 0.720138586109711}\n",
            "{'pmid': '16920333', 'ent_c': 3, 'rel_c': 6, 'g': 0, 'c': 5, 'd': 1, 'v': 0, 'o': 1, 'cl': 0, 'a': 0, 'pc': 1, 'b': 0, 'nc': 2, 'cmp': 3, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.8333333333333334, 'ent_diversity': 3, 'rel_diversity': 3, 'representativeness_score': 0.409884110438935, 'diversity_score': 0.7215812752079771}\n",
            "{'pmid': '17391797', 'ent_c': 5, 'rel_c': 5, 'g': 1, 'c': 2, 'd': 2, 'v': 1, 'o': 1, 'cl': 0, 'a': 3, 'pc': 1, 'b': 0, 'nc': 0, 'cmp': 0, 'cnv': 1, 'ct': 0, 'di': 0, 'novel_ratio': 0.4, 'ent_diversity': 5, 'rel_diversity': 3, 'representativeness_score': 0.5267607259393343, 'diversity_score': 0.7271153055260936}\n",
            "{'pmid': '16309808', 'ent_c': 4, 'rel_c': 7, 'g': 1, 'c': 6, 'd': 3, 'v': 0, 'o': 1, 'cl': 0, 'a': 1, 'pc': 3, 'b': 0, 'nc': 2, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 1, 'novel_ratio': 0.5714285714285714, 'ent_diversity': 4, 'rel_diversity': 4, 'representativeness_score': 0.5064441604905283, 'diversity_score': 0.7300096167820578}\n",
            "{'pmid': '27014915', 'ent_c': 4, 'rel_c': 23, 'g': 16, 'c': 1, 'd': 2, 'v': 0, 'o': 2, 'cl': 0, 'a': 10, 'pc': 6, 'b': 2, 'nc': 5, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.9130434782608695, 'ent_diversity': 4, 'rel_diversity': 4, 'representativeness_score': 0.18678487976497662, 'diversity_score': 0.7301319608568871}\n",
            "{'pmid': '18422462', 'ent_c': 4, 'rel_c': 16, 'g': 2, 'c': 6, 'd': 9, 'v': 0, 'o': 1, 'cl': 0, 'a': 0, 'pc': 3, 'b': 0, 'nc': 5, 'cmp': 0, 'cnv': 0, 'ct': 8, 'di': 0, 'novel_ratio': 0.6875, 'ent_diversity': 4, 'rel_diversity': 3, 'representativeness_score': 0.27611204365843245, 'diversity_score': 0.7304216541483582}\n",
            "{'pmid': '25979836', 'ent_c': 4, 'rel_c': 55, 'g': 19, 'c': 11, 'd': 2, 'v': 0, 'o': 1, 'cl': 0, 'a': 21, 'pc': 25, 'b': 2, 'nc': 7, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.8727272727272727, 'ent_diversity': 4, 'rel_diversity': 4, 'representativeness_score': 0.025831917737644053, 'diversity_score': 0.7319026132853272}\n",
            "{'pmid': '18442015', 'ent_c': 4, 'rel_c': 15, 'g': 1, 'c': 9, 'd': 4, 'v': 0, 'o': 1, 'cl': 0, 'a': 1, 'pc': 11, 'b': 0, 'nc': 2, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 1, 'novel_ratio': 0.6, 'ent_diversity': 4, 'rel_diversity': 4, 'representativeness_score': 0.2916738962129983, 'diversity_score': 0.7327431329682461}\n",
            "{'pmid': '24971338', 'ent_c': 4, 'rel_c': 24, 'g': 9, 'c': 3, 'd': 2, 'v': 0, 'o': 1, 'cl': 0, 'a': 21, 'pc': 1, 'b': 0, 'nc': 1, 'cmp': 1, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 1.0, 'ent_diversity': 4, 'rel_diversity': 4, 'representativeness_score': 0.15860049723338296, 'diversity_score': 0.7442801792246585}\n",
            "{'pmid': '18752389', 'ent_c': 4, 'rel_c': 17, 'g': 2, 'c': 8, 'd': 5, 'v': 0, 'o': 1, 'cl': 0, 'a': 6, 'pc': 7, 'b': 0, 'nc': 3, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 1, 'novel_ratio': 0.8235294117647058, 'ent_diversity': 4, 'rel_diversity': 4, 'representativeness_score': 0.37169417652727205, 'diversity_score': 0.7569427909695015}\n",
            "{'pmid': '17244258', 'ent_c': 4, 'rel_c': 10, 'g': 2, 'c': 12, 'd': 1, 'v': 0, 'o': 1, 'cl': 0, 'a': 3, 'pc': 1, 'b': 0, 'nc': 4, 'cmp': 2, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.3, 'ent_diversity': 4, 'rel_diversity': 4, 'representativeness_score': 0.34232526321177814, 'diversity_score': 0.7575055737137167}\n",
            "{'pmid': '19825989', 'ent_c': 5, 'rel_c': 27, 'g': 13, 'c': 5, 'd': 2, 'v': 0, 'o': 2, 'cl': 2, 'a': 13, 'pc': 3, 'b': 4, 'nc': 7, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.6666666666666666, 'ent_diversity': 5, 'rel_diversity': 4, 'representativeness_score': 0.15521607359479261, 'diversity_score': 0.8051277135456446}\n",
            "{'pmid': '18945509', 'ent_c': 3, 'rel_c': 12, 'g': 0, 'c': 6, 'd': 3, 'v': 0, 'o': 1, 'cl': 0, 'a': 0, 'pc': 3, 'b': 0, 'nc': 5, 'cmp': 4, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.9166666666666666, 'ent_diversity': 3, 'rel_diversity': 3, 'representativeness_score': 0.4131328246991568, 'diversity_score': 0.8097505718016984}\n",
            "{'pmid': '20428796', 'ent_c': 4, 'rel_c': 16, 'g': 8, 'c': 1, 'd': 2, 'v': 0, 'o': 1, 'cl': 0, 'a': 3, 'pc': 4, 'b': 7, 'nc': 2, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.4375, 'ent_diversity': 4, 'rel_diversity': 4, 'representativeness_score': 0.3697593013851675, 'diversity_score': 0.8128693261758911}\n",
            "{'pmid': '21070631', 'ent_c': 5, 'rel_c': 15, 'g': 3, 'c': 2, 'd': 2, 'v': 2, 'o': 1, 'cl': 0, 'a': 12, 'pc': 1, 'b': 0, 'nc': 1, 'cmp': 0, 'cnv': 1, 'ct': 0, 'di': 0, 'novel_ratio': 0.2, 'ent_diversity': 5, 'rel_diversity': 4, 'representativeness_score': 0.44731301735236645, 'diversity_score': 0.8256022857637612}\n",
            "{'pmid': '15630069', 'ent_c': 3, 'rel_c': 17, 'g': 0, 'c': 6, 'd': 4, 'v': 0, 'o': 1, 'cl': 0, 'a': 4, 'pc': 3, 'b': 0, 'nc': 7, 'cmp': 3, 'cnv': 0, 'ct': 0, 'di': 0, 'novel_ratio': 0.5882352941176471, 'ent_diversity': 3, 'rel_diversity': 4, 'representativeness_score': 0.3620367921432515, 'diversity_score': 0.8270092426242992}\n",
            "{'pmid': '16506214', 'ent_c': 5, 'rel_c': 12, 'g': 1, 'c': 2, 'd': 4, 'v': 2, 'o': 1, 'cl': 0, 'a': 7, 'pc': 2, 'b': 0, 'nc': 2, 'cmp': 0, 'cnv': 1, 'ct': 0, 'di': 0, 'novel_ratio': 0.3333333333333333, 'ent_diversity': 5, 'rel_diversity': 4, 'representativeness_score': 0.8217132781191192, 'diversity_score': 0.8411726083537161}\n",
            "{'pmid': '18165598', 'ent_c': 4, 'rel_c': 15, 'g': 4, 'c': 5, 'd': 4, 'v': 0, 'o': 1, 'cl': 0, 'a': 5, 'pc': 6, 'b': 0, 'nc': 2, 'cmp': 1, 'cnv': 0, 'ct': 1, 'di': 0, 'novel_ratio': 1.0, 'ent_diversity': 4, 'rel_diversity': 5, 'representativeness_score': 0.5441181800631238, 'diversity_score': 0.8858200393947919}\n",
            "{'pmid': '17615423', 'ent_c': 4, 'rel_c': 15, 'g': 1, 'c': 14, 'd': 7, 'v': 0, 'o': 2, 'cl': 0, 'a': 1, 'pc': 6, 'b': 0, 'nc': 5, 'cmp': 0, 'cnv': 0, 'ct': 0, 'di': 3, 'novel_ratio': 0.6, 'ent_diversity': 4, 'rel_diversity': 4, 'representativeness_score': 0.2397067874534058, 'diversity_score': 0.9325310071646572}\n",
            "{'pmid': '24927617', 'ent_c': 4, 'rel_c': 13, 'g': 1, 'c': 6, 'd': 4, 'v': 0, 'o': 1, 'cl': 0, 'a': 1, 'pc': 3, 'b': 0, 'nc': 4, 'cmp': 0, 'cnv': 0, 'ct': 3, 'di': 2, 'novel_ratio': 0.38461538461538464, 'ent_diversity': 4, 'rel_diversity': 5, 'representativeness_score': 0.4499468253880889, 'diversity_score': 1.0}\n",
            "[301 319 352  22 322  78 367 151 368  51 371 355 185 373 288 263 339 196\n",
            " 363 359 399]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "train_stat = []\n",
        "\n",
        "for i in range(len(new_train)):\n",
        "  ent_type = {'GeneOrGeneProduct':0, 'ChemicalEntity': 0, 'DiseaseOrPhenotypicFeature': 0, 'SequenceVariant': 0, 'OrganismTaxon': 0, 'CellLine': 0}\n",
        "  rel_type = {'Association': 0, 'Positive_Correlation': 0, 'Bind': 0, 'Negative_Correlation': 0, 'Comparison': 0, 'Conversion': 0, 'Cotreatment': 0, 'Drug_Interaction': 0}\n",
        "  rel_c = 0\n",
        "  novel =0\n",
        "  doc = new_train[str(i)]\n",
        "  for e in doc[\"entities\"]:\n",
        "    ent_type[e[\"type\"]] += 1\n",
        "  for r in doc[\"relation\"]:\n",
        "    rel_type[r[\"infons\"][\"type\"]] += 1\n",
        "    rel_c += 1\n",
        "    if r[\"infons\"][\"novel\"] == \"Novel\":\n",
        "      novel += 1\n",
        "  stat = {\n",
        "      'pmid': doc['pmid'],\n",
        "      'ent_c': sum(value > 0 for value in ent_type.values()),\n",
        "      'rel_c': rel_c,\n",
        "      'g': ent_type['GeneOrGeneProduct'], 'c': ent_type['ChemicalEntity'],'d': ent_type['DiseaseOrPhenotypicFeature'], 'v': ent_type['SequenceVariant'], 'o': ent_type['OrganismTaxon'], 'cl': ent_type['CellLine'],\n",
        "      'a': rel_type['Association'], 'pc': rel_type['Positive_Correlation'], 'b': rel_type['Bind'], 'nc': rel_type['Negative_Correlation'], 'cmp': rel_type['Comparison'], 'cnv': rel_type['Conversion'], 'ct': rel_type['Cotreatment'], 'di': rel_type['Drug_Interaction'],\n",
        "      'novel_ratio': novel/rel_c,\n",
        "      'ent_diversity': sum(value > 0 for value in ent_type.values()),\n",
        "      'rel_diversity': sum(value > 0 for value in rel_type.values())\n",
        "  }\n",
        "  train_stat.append(stat)\n"
      ],
      "metadata": {
        "id": "IdMQp2sjzZZD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lissst = [ent_c, rel_c, g, c, d, v, o, cl, a, pc, b, nc, comp, cnv, ct, di, novel_ratios, ent_diversities, rel_diversities]\n",
        "r = []\n",
        "for l in lissst:\n",
        "  r.append(np.mean(l))\n",
        "print('[ent_c, rel_c, g, c, d, v, o, cl, a, pc, b, nc, comp, cnv, ct, di, novel_ratios, ent_diversities, rel_diversities]')\n",
        "print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhp1PE_VEfkR",
        "outputId": "a2967a22-0346-4c1d-ba07-e3c95019a632"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ent_c, rel_c, g, c, d, v, o, cl, a, pc, b, nc, comp, cnv, ct, di, novel_ratios, ent_diversities, rel_diversities]\n",
            "[3.96, 11.63, 4.25, 2.24, 3.41, 1.39, 1.13, 0.22, 6.35, 3.25, 0.09, 1.71, 0.06, 0.01, 0.14, 0.02, 0.6631150732325763, 3.96, 2.22]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "normalized_rel_c = scaler.fit_transform(np.array(rel_c).reshape(-1, 1)).flatten()\n",
        "print(rel_c)\n",
        "print(normalized_rel_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPneUTkRMlCL",
        "outputId": "fa96ec9b-55cb-4077-eca5-e73718bce43a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18, 3, 15, 7, 4, 11, 48, 3, 1, 12, 14, 12, 2, 6, 4, 15, 15, 7, 11, 11, 19, 32, 31, 8, 107, 2, 1, 5, 5, 7, 11, 10, 6, 45, 2, 4, 12, 6, 2, 17, 6, 15, 10, 43, 4, 7, 5, 13, 4, 23, 15, 5, 6, 9, 4, 7, 23, 4, 2, 7, 5, 6, 7, 29, 12, 2, 1, 41, 8, 11, 6, 11, 21, 8, 8, 14, 7, 2, 11, 6, 11, 6, 17, 5, 3, 4, 25, 12, 5, 10, 24, 6, 10, 1, 14, 8, 4, 5, 6, 8]\n",
            "[0.16037736 0.01886792 0.13207547 0.05660377 0.02830189 0.09433962\n",
            " 0.44339623 0.01886792 0.         0.10377358 0.12264151 0.10377358\n",
            " 0.00943396 0.04716981 0.02830189 0.13207547 0.13207547 0.05660377\n",
            " 0.09433962 0.09433962 0.16981132 0.29245283 0.28301887 0.06603774\n",
            " 1.         0.00943396 0.         0.03773585 0.03773585 0.05660377\n",
            " 0.09433962 0.08490566 0.04716981 0.41509434 0.00943396 0.02830189\n",
            " 0.10377358 0.04716981 0.00943396 0.1509434  0.04716981 0.13207547\n",
            " 0.08490566 0.39622642 0.02830189 0.05660377 0.03773585 0.11320755\n",
            " 0.02830189 0.20754717 0.13207547 0.03773585 0.04716981 0.0754717\n",
            " 0.02830189 0.05660377 0.20754717 0.02830189 0.00943396 0.05660377\n",
            " 0.03773585 0.04716981 0.05660377 0.26415094 0.10377358 0.00943396\n",
            " 0.         0.37735849 0.06603774 0.09433962 0.04716981 0.09433962\n",
            " 0.18867925 0.06603774 0.06603774 0.12264151 0.05660377 0.00943396\n",
            " 0.09433962 0.04716981 0.09433962 0.04716981 0.1509434  0.03773585\n",
            " 0.01886792 0.02830189 0.22641509 0.10377358 0.03773585 0.08490566\n",
            " 0.21698113 0.04716981 0.08490566 0.         0.12264151 0.06603774\n",
            " 0.02830189 0.03773585 0.04716981 0.06603774]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "pairs_data = defaultdict(list)\n",
        "dup =0\n",
        "with open('' , 'r') as file:\n",
        "  content = file.read()\n",
        "  results = content.split('\\n\\n')\n",
        "  for result in results:\n",
        "    lines = result.strip().split('\\n')\n",
        "    pmid = lines[0].split(':')[1].strip(' ')\n",
        "    for line in lines[1:]:\n",
        "      parts = line.split(',')\n",
        "      relation = tuple(parts)\n",
        "      if relation not in pairs_data[pmid]:\n",
        "        pairs_data[pmid].append(relation)\n",
        "      else:\n",
        "        # print(\"duplication: \"+ line + '\\n')\n",
        "        dup+=1"
      ],
      "metadata": {
        "id": "rzsFqZ2gXzeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blocked_docs= [\"27959387\", \"19484664\", \"17935240\"]\n",
        "def create_input(doc):\n",
        "  pmid = doc[\"pmid\"]\n",
        "  input = \"\"\n",
        "  ents = \"\"\n",
        "  for e in doc[\"entities\"]:\n",
        "    ents += '[' + \"/ \".join(e[\"names\"]) + ']' + \",\" + e[\"id\"]+ \",\"  + e[\"type\"] + \"\\n\"\n",
        "  pairs = \"\"\n",
        "  for p in pairs_data[pmid]:\n",
        "    pairs+= p + '\\n'\n",
        "  # example += \"pmid:\" + doc[\"pmid\"] +\"\\n\"\n",
        "  input += doc[\"title\"] +\"\\n\"\n",
        "  input += doc[\"article\"] +\"\\n\"\n",
        "  input +=  ents +\"\\n\\n\"\n",
        "  input + \"entity pairs:\\n\"\n",
        "  input += pairs\n",
        "  return input"
      ],
      "metadata": {
        "id": "ZZV2pmWPWTyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_tune_dataset(filename, pairs_only):\n",
        "  # zero_docs = [128,169,205,315,323]\n",
        "  # docs = docs = list(set(range(0,len(filename))) - set(zero_docs))\n",
        "  docs = list(set(range(0,len(filename))))\n",
        "\n",
        "  examples=[]\n",
        "\n",
        "  for i in docs:\n",
        "    input = \"\"\n",
        "    output = \"\"\n",
        "    doc = filename[str(i)]\n",
        "    ents = \"\"\n",
        "    for e in doc[\"entities\"]:\n",
        "      ents += '[' + \"/ \".join(e[\"names\"]) + ']' + \",\" + e[\"id\"]+ \",\"  + e[\"type\"] + \"\\n\"\n",
        "\n",
        "    if pairs_only:\n",
        "      out = \"\"\n",
        "      for r in doc[\"relation\"]:\n",
        "        ent1=r[\"infons\"][\"entity1\"]\n",
        "        ent2 = r[\"infons\"][\"entity2\"]\n",
        "        if ent1 <= ent2:\n",
        "          out += ent1 + \",\" + ent2 + \"\\n\"\n",
        "        else:\n",
        "          out += ent2 + \",\" + ent1 + \"\\n\"\n",
        "    else:\n",
        "      out = \"\"\n",
        "      for r in doc[\"relation\"]:\n",
        "        ent1=r[\"infons\"][\"entity1\"]\n",
        "        ent2 = r[\"infons\"][\"entity2\"]\n",
        "        if ent1 <= ent2:\n",
        "          out += r[\"infons\"][\"type\"]+ \",\" + ent1 + \",\" + ent2 + \",\" + r[\"infons\"][\"novel\"] + \"\\n\"\n",
        "        else:\n",
        "          out += r[\"infons\"][\"type\"]+ \",\" + ent2 + \",\" + ent1 + \",\" + r[\"infons\"][\"novel\"] + \"\\n\"\n",
        "\n",
        "\n",
        "    # example += \"pmid:\" + doc[\"pmid\"] +\"\\n\"\n",
        "    input = doc[\"title\"] +\"\\n\"\n",
        "    input += doc[\"article\"] +\"\\n\"\n",
        "    input +=  ents\n",
        "    output = out\n",
        "    example = [input, output]\n",
        "    examples.append(example)\n",
        "\n",
        "  return examples\n",
        "\n"
      ],
      "metadata": {
        "id": "_kZKI9-520b6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "file_name = \"train_ds_pair_no_ins.jsonl\"\n",
        "rows = create_tune_dataset(new_train, True)\n",
        "with open(file_name, \"a\") as outfile:\n",
        "  for i, row in enumerate(rows):\n",
        "    new_data = {\"messages\": [{\"role\": \"user\",\"content\": row[0]},{\"role\": \"model\",\"content\": row[1]}]}\n",
        "    prompt_token = len(str(new_data))\n",
        "    if prompt_token > 321767 or len(row[0]) > 8191 or len(row[1]) > 8191 :\n",
        "      print(i)\n",
        "      print(prompt_token, len(row[0]), len(row[1]))\n",
        "\n",
        "    else:\n",
        "      print(json.dumps(new_data), file=outfile)"
      ],
      "metadata": {
        "id": "eDYSbb3z9ZQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = create_tune_dataset(new_dev, False)\n",
        "filename = \"dev_readable.txt\"\n",
        "with open(filename, 'a') as f:\n",
        "  for i,d in enumerate(data):\n",
        "    f.write(str(i)+ '\\n' +d[0]+'\\n'+d[1] + '\\n')\n",
        "\n",
        "data = create_tune_dataset(new_test, False)\n",
        "filename = \"test_readable.txt\"\n",
        "with open(filename, 'a') as f:\n",
        "  for i,d in enumerate(data):\n",
        "    f.write(str(i)+ '\\n' +d[0]+'\\n'+d[1] + '\\n')\n",
        "\n",
        "data = create_tune_dataset(new_train, False)\n",
        "filename = \"train_readable.txt\"\n",
        "with open(filename, 'a') as f:\n",
        "  for i,d in enumerate(data):\n",
        "    f.write(str(i)+ '\\n' +d[0]+'\\n'+d[1] + '\\n')"
      ],
      "metadata": {
        "id": "QtQw8PxFFvaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "# field names\n",
        "fields = ['input:', 'output:']\n",
        "# data rows of csv file\n",
        "rows = create_tune_dataset(new_dev, True)\n",
        "# name of csv file\n",
        "filename = \"dev_tune_pairs_20.csv\"\n",
        "# writing to csv file\n",
        "with open(filename, 'w') as csvfile:\n",
        "    # creating a csv writer object\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "    # writing the fields\n",
        "    csvwriter.writerow(fields)\n",
        "    # writing the data rows\n",
        "    csvwriter.writerows(rows)"
      ],
      "metadata": {
        "id": "rZNuGb1CnBJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('/content/new_train.json') as file:\n",
        "    new_train = json.load(file)"
      ],
      "metadata": {
        "id": "3Y8JWeiXW_2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83Ujpwyh-jDD"
      },
      "outputs": [],
      "source": [
        "with open('/content/new_dev100.json') as file:\n",
        "    new_dev = json.load(file)\n",
        "with open('/content/new_train.json') as file:\n",
        "    new_train = json.load(file)\n",
        "with open('/content/new_test.json') as file:\n",
        "    new_test = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsXx-J4nKHeR"
      },
      "outputs": [],
      "source": [
        "print(create_one_example(363, new_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eip2H2N4Uvwf"
      },
      "outputs": [],
      "source": [
        "def create_one_example(id, filename):\n",
        "  i = id\n",
        "\n",
        "  example = \"\"\n",
        "  doc = filename[str(i)]\n",
        "  ents = \"\"\n",
        "  for e in doc[\"entities\"]:\n",
        "    ents += '[' + \"/ \".join(e[\"names\"]) + ']' + \",\" + e[\"id\"]+ \",\"  + e[\"type\"] + \"\\n\"\n",
        "  rels = \"\"\n",
        "  for r in doc[\"relation\"]:\n",
        "    rels += r[\"infons\"][\"type\"]+ \",\" + r[\"infons\"][\"entity1\"]+ \",\" + r[\"infons\"][\"entity2\"]+ \",\" + r[\"infons\"][\"novel\"] + \"\\n\"\n",
        "    # rels += entity_id_to_name(doc, r)\n",
        "\n",
        "  # example += \"pmid:\" + doc[\"pmid\"] +\"\\n\"\n",
        "  example += doc[\"title\"] +\"\\n\"\n",
        "  example += doc[\"article\"] +\"\\n\"\n",
        "  example += \"\\n\" + ents +\"\\n\"\n",
        "  # example += \"pmid:\" + doc[\"pmid\"] +\"\\n\"\n",
        "  example += rels +\"\\n\\n\"\n",
        "\n",
        "\n",
        "  return example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGycgf5NVwTc"
      },
      "outputs": [],
      "source": [
        "for rel in new_dev['0'][\"relation\"] :\n",
        "  print(rel['infons'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG3curlXTjDf",
        "outputId": "6331d1d1-7f2c-408f-a692-86ce5e28b0ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: {'pmid': '14510914', 'types_count': defaultdict(<class 'int'>, {'Positive_Correlation': 4, 'Association': 4, 'Negative_Correlation': 4}), 'novelty_count': defaultdict(<class 'int'>, {'Novel': 7, 'No': 5}), 'rel_c': 12, 'tokens': 365}, 1: {'pmid': '15096016', 'types_count': defaultdict(<class 'int'>, {'Positive_Correlation': 1}), 'novelty_count': defaultdict(<class 'int'>, {'No': 1}), 'rel_c': 1, 'tokens': 203}}\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "file_name = new_dev\n",
        "\n",
        "stats = {}\n",
        "\n",
        "file_type_c, file_novel_c = defaultdict(int), defaultdict(int)\n",
        "file_rel = 0\n",
        "\n",
        "for i in range(len(file_name)):\n",
        "  doc = file_name[str(i)]\n",
        "  pmid = doc['pmid']\n",
        "  rel_c, tokens =0,0\n",
        "  type_c, novel_c = defaultdict(int), defaultdict(int)\n",
        "  tokens = len(create_one_example(i, file_name).split())\n",
        "  for rel in doc['relation']:\n",
        "    rel_type = rel['infons']['type']\n",
        "    novelty = rel['infons']['novel']\n",
        "    type_c[rel_type] +=1\n",
        "    file_type_c[rel_type] +=1\n",
        "    novel_c[novelty] +=1\n",
        "    file_novel_c[novelty] +=1\n",
        "    rel_c += 1\n",
        "    file_rel +=1\n",
        "  stats[i] = {\n",
        "      'pmid': pmid,\n",
        "      'types_count': type_c,\n",
        "      'novelty_count': novel_c,\n",
        "      'rel_c': rel_c,\n",
        "      'tokens': tokens\n",
        "  }\n",
        "\n",
        "print(stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkmfItutdRNK"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "dev:\n",
        "Total number of relations: 1162\n",
        "Relation type counts: {'Positive_Correlation': 352, 'Association': 560, 'Negative_Correlation': 216, 'Bind': 19, 'Cotreatment': 10, 'Comparison': 5}\n",
        "Novelty counts: {'Novel': 835, 'No': 327}\n",
        "\n",
        "train:\n",
        "Total number of relations: 4178\n",
        "Relation type counts: {'Association': 2192, 'Positive_Correlation': 1089, 'Bind': 61, 'Negative_Correlation': 763, 'Comparison': 28, 'Conversion': 3, 'Cotreatment': 31, 'Drug_Interaction': 11}\n",
        "Novelty counts: {'No': 1340, 'Novel': 2838}\n",
        "\n",
        "test:\n",
        "Total number of relations: 1163\n",
        "Relation type counts: {'Association': 635, 'Positive_Correlation': 325, 'Negative_Correlation': 171, 'Comparison': 6, 'Bind': 9, 'Conversion': 1, 'Cotreatment': 14, 'Drug_Interaction': 2}\n",
        "Novelty counts: {'Novel': 859, 'No': 304}\n",
        "'''\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJ1KD4fFcAoq"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "file_name = new_train\n",
        "stats = {}\n",
        "file_type_c = Counter()\n",
        "file_novel_c = Counter()\n",
        "file_rel, file_tokens = 0,0\n",
        "\n",
        "for i in range(4):\n",
        "    print(i)\n",
        "    doc = file_name[str(i)]\n",
        "    pmid = doc['pmid']\n",
        "    rel_c = 0\n",
        "    type_c = Counter()\n",
        "    novel_c = Counter()\n",
        "    tokens = len(create_one_example(i, file_name).split())\n",
        "    file_tokens +=tokens\n",
        "    for rel in doc['relation']:\n",
        "        rel_type = rel['infons']['type']\n",
        "        novelty = rel['infons']['novel']\n",
        "        print(rel)\n",
        "        type_c[rel_type] += 1\n",
        "        file_type_c[rel_type] += 1\n",
        "        novel_c[novelty] += 1\n",
        "        print(novel_c)\n",
        "        file_novel_c[novelty] += 1\n",
        "        print(file_novel_c)\n",
        "        rel_c += 1\n",
        "        file_rel += 1\n",
        "\n",
        "    stats[i] = {\n",
        "        'pmid': pmid,\n",
        "        'types_count': dict(type_c),\n",
        "        'novelty_count': dict(novel_c),\n",
        "        'rel_c': rel_c,\n",
        "        'tokens': tokens\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp-AIFNffJ6H",
        "outputId": "75c99948-0467-4620-ee6e-05079d8e81d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of relations: 1163\n",
            "Total number of tokens: 27880\n",
            "Relation type counts: {'Association': 635, 'Positive_Correlation': 325, 'Negative_Correlation': 171, 'Comparison': 6, 'Bind': 9, 'Conversion': 1, 'Cotreatment': 14, 'Drug_Interaction': 2}\n",
            "Novelty counts: {'Novel': 859, 'No': 304}\n"
          ]
        }
      ],
      "source": [
        "# Get the relation type you want to see\n",
        "target_rel_type = 'Bind'\n",
        "\n",
        "# Sort documents based on the target relation type count\n",
        "sorted_docs = sorted(stats.items(), key=lambda x: x[1]['types_count'].get(target_rel_type, 0), reverse=True)\n",
        "\n",
        "# Print information\n",
        "print(f\"Total number of relations: {file_rel}\")\n",
        "print(f\"Total number of tokens: {file_tokens}\")\n",
        "print(f\"Relation type counts: {dict(file_type_c)}\")\n",
        "print(f\"Novelty counts: {dict(file_novel_c)}\")\n",
        "\n",
        "\n",
        "# print(f\"\\nDocuments with the most '{target_rel_type}' relation type:\")\n",
        "# for doc_idx, doc_stats in sorted_docs:\n",
        "#     # if doc_stats['types_count'].get(target_rel_type, 0) > 0:\n",
        "#         print(f\"\\nDocument {doc_idx} (PMID: {doc_stats['pmid']})\")\n",
        "#         print(f\"Number of relations: {doc_stats['rel_c']}\")\n",
        "#         print(f\"Number of tokens: {doc_stats['tokens']}\")\n",
        "#         print(f\"Relation type counts: {doc_stats['types_count']}\")\n",
        "#         print(f\"Novelty counts: {doc_stats['novelty_count']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9ROq82ujWcR"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import openpyxl\n",
        "\n",
        "file_name = new_test\n",
        "stats = {}\n",
        "file_type_c = Counter()\n",
        "file_novel_c = Counter()\n",
        "file_rel= 0\n",
        "\n",
        "for i in range(len(file_name)):\n",
        "    doc = file_name[str(i)]\n",
        "    pmid = doc['pmid']\n",
        "    rel_c = 0\n",
        "    type_c = Counter()\n",
        "    novel_c = Counter()\n",
        "    tokens = len(create_one_example(i, file_name).split())\n",
        "\n",
        "\n",
        "    for rel in doc['relation']:\n",
        "        rel_type = rel['infons']['type']\n",
        "        novelty = rel['infons']['novel']\n",
        "        type_c[rel_type] += 1\n",
        "        file_type_c[rel_type] += 1\n",
        "        novel_c[novelty] += 1\n",
        "        file_novel_c[novelty] += 1\n",
        "        rel_c += 1\n",
        "        file_rel += 1\n",
        "\n",
        "    stats[i] = {\n",
        "        'pmid': pmid,\n",
        "        'types_count': dict(type_c),\n",
        "        'novelty_count': dict(novel_c),\n",
        "        'rel_c': rel_c,\n",
        "        'tokens': tokens\n",
        "    }\n",
        "\n",
        "# Create a new workbook\n",
        "workbook = openpyxl.Workbook()\n",
        "worksheet = workbook.active\n",
        "\n",
        "# Write the header row\n",
        "header = ['id', 'relation_count', 'tokens'] + list(file_type_c.keys()) + list(file_novel_c.keys())\n",
        "worksheet.append(header)\n",
        "\n",
        "# Write the data rows\n",
        "for doc_idx, doc_stats in stats.items():\n",
        "    row = [doc_idx, doc_stats['rel_c'], doc_stats['tokens']]\n",
        "    for rel_type in file_type_c.keys():\n",
        "        row.append(doc_stats['types_count'].get(rel_type, 0))\n",
        "    for nov in file_novel_c.keys():\n",
        "        row.append(doc_stats['novelty_count'].get(nov, 0))\n",
        "    # row.append(sum(doc_stats['novelty_count'].values()))\n",
        "    # row.append(doc_stats['novelty_count'].get('No', 0))\n",
        "    worksheet.append(row)\n",
        "\n",
        "# Save the workbook\n",
        "workbook.save('output.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvVvp9YQ_ur8"
      },
      "outputs": [],
      "source": [
        "def create_output(doc):\n",
        "  output = \"\"\n",
        "  rels = \"\"\n",
        "  for r in doc[\"relation\"]:\n",
        "      if r[\"infons\"][\"entity1\"] <= r[\"infons\"][\"entity2\"]:\n",
        "        ent1 = r[\"infons\"][\"entity1\"]\n",
        "        ent2 = r[\"infons\"][\"entity2\"]\n",
        "      else:\n",
        "        ent1 = r[\"infons\"][\"entity2\"]\n",
        "        ent2 = r[\"infons\"][\"entity1\"]\n",
        "\n",
        "      rels += r[\"infons\"][\"type\"]+ \",\" + ent1 + \",\" + ent2 + \",\" + r[\"infons\"][\"novel\"] + \"\\n\"\n",
        "  output += \"pmid:\" + doc[\"pmid\"] +\"\\n\"\n",
        "  output += rels +\"\\n\\n\"\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cf2BoTtTtsDt"
      },
      "outputs": [],
      "source": [
        "output = \"\"\n",
        "for i in range(len(new_test)):\n",
        "  rels = \"\"\n",
        "  doc = new_test[str(i)]\n",
        "  for r in doc[\"relation\"]:\n",
        "      if r[\"infons\"][\"entity1\"] <= r[\"infons\"][\"entity2\"]:\n",
        "        ent1 = r[\"infons\"][\"entity1\"]\n",
        "        ent2 = r[\"infons\"][\"entity2\"]\n",
        "      else:\n",
        "        ent1 = r[\"infons\"][\"entity2\"]\n",
        "        ent2 = r[\"infons\"][\"entity1\"]\n",
        "\n",
        "      rels += r[\"infons\"][\"type\"]+ \",\" + ent1 + \",\" + ent2 + \",\" + r[\"infons\"][\"novel\"] + \"\\n\"\n",
        "  output += \"pmid:\" + doc[\"pmid\"] +\"\\n\"\n",
        "  output += rels +\"\\n\\n\"\n",
        "  i += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test output for pairs\n",
        "output = \"\"\n",
        "for i in range(len(new_test)):\n",
        "  rels = \"\"\n",
        "  doc = new_test[str(i)]\n",
        "  for r in doc[\"relation\"]:\n",
        "      if r[\"infons\"][\"entity1\"] <= r[\"infons\"][\"entity2\"]:\n",
        "        ent1 = r[\"infons\"][\"entity1\"]\n",
        "        ent2 = r[\"infons\"][\"entity2\"]\n",
        "      else:\n",
        "        ent1 = r[\"infons\"][\"entity2\"]\n",
        "        ent2 = r[\"infons\"][\"entity1\"]\n",
        "\n",
        "      rels +=  ent1 + \",\" + ent2 + \"\\n\"\n",
        "  output += \"pmid:\" + doc[\"pmid\"] +\"\\n\"\n",
        "  output += rels +\"\\n\\n\"\n",
        "  i += 1"
      ],
      "metadata": {
        "id": "O7Rxk6JfJoIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOa-gNhI0I3G"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/expected.txt\", \"w\") as f:\n",
        "    f.write(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ALbTlP-RTdg"
      },
      "outputs": [],
      "source": [
        "def entity_id_to_name(doc, r):\n",
        "  ent1_name = \"\"\n",
        "  ent2_name = \"\"\n",
        "  for e in doc[\"entities\"]:\n",
        "    if r[\"infons\"][\"entity1\"] == e[\"id\"]:\n",
        "      ent1_name = '[' + \"/ \".join(e[\"names\"]) + ']'\n",
        "  for e in doc[\"entities\"]:\n",
        "    if r[\"infons\"][\"entity2\"] == e[\"id\"]:\n",
        "      ent2_name = '[' + \"/ \".join(e[\"names\"]) + ']'\n",
        "  return r[\"infons\"][\"type\"]+ \",\" + ent1_name + \",\" + ent2_name + \",\" + r[\"infons\"][\"novel\"] + \"\\n\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovJvX6__0mYe"
      },
      "outputs": [],
      "source": [
        "def convert_examples(filename):\n",
        "  pubmed = {}\n",
        "  for index, doc in enumerate(filename[\"documents\"]):\n",
        "    annotations = [doc[\"passages\"][0][\"annotations\"], doc[\"passages\"][1][\"annotations\"]]\n",
        "    pubmed[index]= {\n",
        "        \"pmid\" : doc[\"id\"],\n",
        "        \"title\": doc[\"passages\"][0][\"text\"],\n",
        "        \"article\": doc[\"passages\"][1][\"text\"],\n",
        "        \"entities\": [],\n",
        "        \"relation\": doc[\"relations\"]\n",
        "    }\n",
        "\n",
        "\n",
        "    i = 0\n",
        "    for annotation in annotations:\n",
        "      for entity in annotation:\n",
        "          new_e = True\n",
        "          identifier = entity[\"infons\"][\"identifier\"]\n",
        "          name = entity[\"text\"]\n",
        "          entity_type = entity[\"infons\"][\"type\"]\n",
        "\n",
        "          for e in pubmed[index][\"entities\"]:\n",
        "              if identifier == e[\"id\"]:\n",
        "                  new_e = False\n",
        "                  if name.lower() not in [n.lower() for n in e[\"names\"]]:\n",
        "                    e[\"names\"].append(name)\n",
        "                  break\n",
        "\n",
        "          if new_e or i ==0:\n",
        "              entities[i] = {\n",
        "                  \"id\": identifier,\n",
        "                  \"names\": [name],\n",
        "                  \"type\": entity_type\n",
        "              }\n",
        "              pubmed[index][\"entities\"].append(entities[i])\n",
        "              i += 1\n",
        "  return pubmed\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "1e-9jg4CliOt",
        "outputId": "5a9352fc-7cbd-448d-b872-eea0c40282db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18257781\n",
            "Co-inheritance of a PKD1 mutation and homozygous PKD2 variant: a potential modifier in autosomal dominant polycystic kidney disease.\n",
            "BACKGROUND: Autosomal dominant polycystic kidney disease (ADPKD), which is caused by mutations in polycystins 1 (PC1) and 2 (PC2), is one of the most commonly inherited renal diseases, affecting ~1 : 1000 Caucasians. MATERIALS AND METHODS: We screened Greek ADPKD patients with the denaturing gradient gel electrophoresis (DGGE) assay and direct sequencing. RESULTS: We identified a patient homozygous for a nucleotide change c.1445T > G, resulting in a novel homozygous substitution of the non-polar hydrophobic phenylalanine to the polar hydrophilic cysteine in exon 6 at codon 482 (p.F482C) of the PKD2 gene and a de-novo PKD1 splice-site variant IVS21-2delAG. We did not find this PKD2 variant in a screen of 280 chromosomes of healthy subjects, supporting its pathogenicity. The proband's parents did not have the PKD1 mutation. Real-time PCR of the PKD2 transcript from a skin biopsy revealed 20-fold higher expression in the patient than in a healthy subject and was higher in the patient's peripheral blood mononuclear cells (PBMCs) than in those of her heterozygote daughter and a healthy subject. The greater gene expression was also supported by Western blotting. Inner medullar collecting duct (IMCD) cells transfected with the mutant PKD2 mouse gene presented a perinuclear and diffuse cytoplasmic localization compared with the wild type ER localization. Patch-clamping of PBMCs from the p.F482C homozygous and heterozygous subjects revealed lower polycystin-2 channel function than in controls. CONCLUSIONS: We report for the first time a patient with ADPKD who is heterozygous for a de novo PKD1 variant and homozygous for a novel PKD2 mutation.\n",
            "[PKD1/ polycystins 1/ PC1],5310,GeneOrGeneProduct\n",
            "[PKD2/ PC2/ polycystin-2],5311,GeneOrGeneProduct\n",
            "[autosomal dominant polycystic kidney disease/ ADPKD],D007690,DiseaseOrPhenotypicFeature\n",
            "[renal diseases],D007674,DiseaseOrPhenotypicFeature\n",
            "[patients/ patient],9606,OrganismTaxon\n",
            "[c.1445T > G/ phenylalanine to the polar hydrophilic cysteine in exon 6 at codon 482/ p.F482C],rs75762896,SequenceVariant\n",
            "[IVS21-2delAG],c|DEL|IVS21-2|AG,SequenceVariant\n",
            "[PKD2],18764,GeneOrGeneProduct\n",
            "[mouse],10090,OrganismTaxon\n",
            "\n",
            "\n",
            "pmid:18257781\n",
            "Positive_Correlation,5311,rs75762896,Novel\n",
            "Association,5311,D007690,Novel\n",
            "Association,5310,D007690,Novel\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "inputs = create_inputs()\n",
        "outputs = \"\"\n",
        "prompt = add_exaples_prompt(init_prompt)\n",
        "i = 35\n",
        "print(new_test[str(i)][\"pmid\"])\n",
        "print(inputs[i])\n",
        "prompt += \"produce similar output(pmid, relations) for this article:\" + '\\n'\n",
        "prompt += inputs[i]\n",
        "response = model.generate_content(prompt)\n",
        "outputs += \"pmid:\" + new_test[str(i)][\"pmid\"]+ \"\\n\" + response.text + \"\\n\\n\"\n",
        "\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz6eQEFPH3Jd",
        "outputId": "bbe891d4-1184-43f1-ad79-6b42c9e855d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pmid:18257781\n",
            "Positive_Correlation,D007690,c|DEL|IVS21-2|AG,Novel\n",
            "Association,5311,D007690,No\n",
            "Association,5310,D007690,No\n",
            "Positive_Correlation,D007690,rs75762896,Novel\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(create_output(new_test[str(35)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WShED1-EkbIV"
      },
      "outputs": [],
      "source": [
        "init_prompt---- = '''\n",
        "you are a helpful assistants in extracting biomedical relations from biomedical articles. your task is to find relations and produce structured results. each relation has tow entities and it has specific relation type. here is the entity and relation types and their definition.:\n",
        "Based on the BioRED corpus, here are short definitions for the 8 relation types:\n",
        "\n",
        "Association: The relation between two entities where the association cannot be categorized as positive or negative correlation, or the description is unclear.\n",
        "Comparison: The relation that compares the effects or properties of two chemicals or drugs.\n",
        "Conversion: A chemical is transformed or converted into another chemical through a chemical reaction or process.\n",
        "Cotreatment: The use of two or more chemicals/drugs together as a combination therapy for treating a disease or condition.\n",
        "Negative_Correlation: A relation indicating an inverse or opposing effect between two entities, such as a chemical decreasing the expression of a gene, or a variant causing resistance to a drug.\n",
        "Positive_Correlation: A relation indicating a direct or reinforcing effect between two entities, such as a chemical increasing the expression of a gene, or a variant causing sensitivity to a drug.\n",
        "Bind: A physical interaction or binding between two entities, such as a chemical binding to a gene or its protein product.\n",
        "Drug_Interaction: A pharmacological interaction that occurs when two drugs are administered together, potentially affecting their efficacy or side effects.\n",
        "\n",
        "Here are short descriptions for the 6 entity types in the BioRED corpus:\n",
        "(1) Gene: This entity type includes genes, proteins, mRNA, and other gene products. Entity linking is performed to map gene mentions to specific NCBI Gene identifiers.\n",
        "(2) Chemical: This covers chemicals and drugs. Chemical mentions are linked to MeSH identifiers.\n",
        "(3) Disease: This includes diseases, symptoms, and some disease-related phenotypes. Disease mentions are mapped to concept identifiers from a combination of MeSH and OMIM.\n",
        "(4) Variant: This represents genomic and protein variants, including substitutions, deletions, insertions, and others. Variant mentions are normalized to dbSNP accession numbers or their component representations when an identifier is not available.\n",
        "(5) Species: This covers species names from the hierarchical taxonomy of organisms. Species mentions are linked to NCBI Taxonomy identifiers.\n",
        "(6) CellLine: This represents cell line names. Cell line mentions are mapped to identifiers from the Cellosaurus database.\n",
        "\n",
        "novelty:\n",
        "Novel: It is used for relations that are related to the main point or novelty of the abstract. Any information that would be part of the results or conclusions of the paper is considered novel.\n",
        "No: It is for relations that are background information, typically providing context for the abstract, such as results of previous studies or relevant details that are needed to understand why the paper is important:\n",
        "\n",
        "the input is the article and the entities with their name and type and an identifier. first line:title second line: article then entities in this format([entity names],entity id,type) the output is like this: relation type,entity1,entity2,novelty :\n",
        "\n",
        "\n",
        "Curcumin prevents maleate-induced nephrotoxicity: relation to hemodynamic alterations, oxidative stress, mitochondrial oxygen consumption and activity of respiratory complex I.\n",
        "The potential protective effect of the dietary antioxidant curcumin (120 mg/Kg/day for 6 days) against the renal injury induced by maleate was evaluated. Tubular proteinuria and oxidative stress were induced by a single injection of maleate (400 mg/kg) in rats. Maleate-induced renal injury included increase in renal vascular resistance and in the urinary excretion of total protein, glucose, sodium, neutrophil gelatinase-associated lipocalin (NGAL) and N-acetyl b-D-glucosaminidase (NAG), upregulation of kidney injury molecule (KIM)-1, decrease in renal blood flow and claudin-2 expression besides of necrosis and apoptosis of tubular cells on 24 h. Oxidative stress was determined by measuring the oxidation of lipids and proteins and diminution in renal Nrf2 levels. Studies were also conducted in renal epithelial LLC-PK1 cells and in mitochondria isolated from kidneys of all the experimental groups. Maleate induced cell damage and reactive oxygen species (ROS) production in LLC-PK1 cells in culture. In addition, maleate treatment reduced oxygen consumption in ADP-stimulated mitochondria and diminished respiratory control index when using malate/glutamate as substrate. The activities of both complex I and aconitase were also diminished. All the above-described alterations were prevented by curcumin. It is concluded that curcumin is able to attenuate in vivo maleate-induced nephropathy and in vitro cell damage. The in vivo protection was associated to the prevention of oxidative stress and preservation of mitochondrial oxygen consumption and activity of respiratory complex I, and the in vitro protection was associated to the prevention of ROS production.\n",
        "\n",
        "[Curcumin],D003474,ChemicalEntity\n",
        "[maleate],C030272,ChemicalEntity\n",
        "[nephrotoxicity/ renal injury/ nephropathy],D007674,DiseaseOrPhenotypicFeature\n",
        "[oxygen],D010100,ChemicalEntity\n",
        "[respiratory complex I],D042967,ChemicalEntity\n",
        "[proteinuria],D011507,DiseaseOrPhenotypicFeature\n",
        "[rats],10116,OrganismTaxon\n",
        "[glucose],D005947,ChemicalEntity\n",
        "[sodium],D012964,ChemicalEntity\n",
        "[neutrophil gelatinase-associated lipocalin/ NGAL],170496,GeneOrGeneProduct\n",
        "[N-acetyl b-D-glucosaminidase/ NAG],-,GeneOrGeneProduct\n",
        "[kidney injury molecule (KIM)-1],286934,GeneOrGeneProduct\n",
        "[claudin-2],733684,GeneOrGeneProduct\n",
        "[necrosis and apoptosis of tubular cells],D007673,DiseaseOrPhenotypicFeature\n",
        "[lipids],D008055,ChemicalEntity\n",
        "[Nrf2],83619,GeneOrGeneProduct\n",
        "[LLC-PK1],CVCL_0391,CellLine\n",
        "[reactive oxygen species/ ROS],D017382,ChemicalEntity\n",
        "[ADP],D000244,ChemicalEntity\n",
        "[malate],C030298,ChemicalEntity\n",
        "[glutamate],D018698,ChemicalEntity\n",
        "[aconitase],50655,GeneOrGeneProduct\n",
        "\n",
        "Positive_Correlation,D011507,C030272,Novel\n",
        "Positive_Correlation,D007674,286934,Novel\n",
        "Negative_Correlation,D007674,733684,Novel\n",
        "Association,D007674,170496,Novel\n",
        "Association,D007674,D012964,Novel\n",
        "Association,D007674,D005947,Novel\n",
        "Negative_Correlation,C030272,50655,Novel\n",
        "Association,C030272,D010100,Novel\n",
        "Positive_Correlation,C030272,D017382,Novel\n",
        "Positive_Correlation,C030272,286934,Novel\n",
        "Negative_Correlation,C030272,733684,Novel\n",
        "Association,C030272,170496,Novel\n",
        "Association,C030272,D012964,Novel\n",
        "Association,C030272,D005947,Novel\n",
        "Positive_Correlation,C030272,D007674,No\n",
        "Negative_Correlation,D003474,D007674,Novel\n",
        "Negative_Correlation,D003474,C030272,Novel\n",
        "\n",
        "Considarations: the output only should have the relations in the mentioned structure! each entity pair only has one relation.\n",
        "'''"
      ]
    }
  ]
}